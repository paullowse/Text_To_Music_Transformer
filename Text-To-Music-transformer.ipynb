{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "158a886c-b409-4cc2-a0b3-2dadc6d5ff1e",
   "metadata": {},
   "source": [
    "# Text to Music Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cd5b22-0df4-464e-b7cb-e4913f2df8ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dependencies - run once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91d42d4d-2dee-4361-ad07-df6e003f326b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install miditok==2.1.8 torchmetrics\n",
    "# !pip install miditoolkit \n",
    "# !pip install datasets\n",
    "# !pip install transformers\n",
    "# !pip install accelerate -U\n",
    "# !pip install tensorrt\n",
    "# !pip install tensorboardX\n",
    "# !pip install fairseq\n",
    "\n",
    "# !pip install utils\n",
    "# !pip install torch\n",
    "# !pip install unidecode\n",
    "\n",
    "# !pip install ipywidgets\n",
    "# !jupyter labextension install @jupyter-widgets/jupyterlab-manager\n",
    "\n",
    "# # !pip install torch - takes 15-18 mins\n",
    "# !pip install git+https://github.com/idiap/fast-transformers\n",
    "\n",
    "# !pip install torch==2.0.0+cu117 torchvision==0.15.1+cu117 torchaudio==2.0.1 --index-url https://download.pytorch.org/whl/cu117"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236c2bf4-ddb7-451b-9d10-cdb3fef9615e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77247b01-339f-4759-81f1-363f5e3ed8ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Cuda\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import time\n",
    "import argparse\n",
    "import subprocess\n",
    "from utils import *\n",
    "from transformers import AutoTokenizer, RobertaConfig, RobertaModel\n",
    "import torch\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import math\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from unidecode import unidecode\n",
    "from transformers import AutoModel, AutoConfig, PreTrainedModel\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "from miditok import Octuple, TokenizerConfig\n",
    "from miditoolkit import MidiFile\n",
    "from fast_transformers.builders import TransformerEncoderBuilder\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parallel import DataParallel\n",
    "from fast_transformers.masking import TriangularCausalMask\n",
    "\n",
    "torch.manual_seed(5)\n",
    "\n",
    "start_setup_time = time.time()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print('Using Cuda')\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        \n",
    "    return device\n",
    "    \n",
    "def get_filtered_files(directory_path, exclude_list):\n",
    "    file_list = os.listdir(directory_path)\n",
    "    filtered_list = [file_name for file_name in file_list if file_name not in exclude_list]\n",
    "    return filtered_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa54144c-37d9-4592-a1cf-a5b14feac53c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ------ New Constants ------\n",
    "batch_size = 4\n",
    "ngpus = 4\n",
    "\n",
    "music_EOS_token = [[2,2,2,2,2,2]] # according to the vocab\n",
    "music_SOS_token = [1,1,1,1,1,1] # according to the vocab\n",
    "\n",
    "music_EOS_tensor = torch.tensor(music_EOS_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8571fa05-33d0-4389-b30b-467666a3bb56",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "# Confirming size of dataset\n",
    "print(len(get_filtered_files('dataset/midi_partial', ['.ipynb_checkpoints', '.DS_Store'])))\n",
    "print(len(get_filtered_files('dataset/text_partial', ['.ipynb_checkpoints', '.DS_Store'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d8eb846-c2de-40c4-adca-6375ce8ad948",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Train_Dataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.text_files = get_filtered_files('dataset/text_partial', ['.ipynb_checkpoints', '.DS_Store'])\n",
    "        self.midi_files = get_filtered_files('dataset/midi_partial', ['.ipynb_checkpoints', '.DS_Store'])\n",
    "        self.text_tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "        self.midi_tokenizer = Octuple(TokenizerConfig(use_programs=True))\n",
    "\n",
    "        # Calculate the number of files to use for training (90% of the total)\n",
    "        self.train_size = int(0.8 * len(self.midi_files))\n",
    "        self.text_files = self.text_files[:self.train_size]\n",
    "        self.midi_files = self.midi_files[:self.train_size]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.midi_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text_file = self.text_files[idx]\n",
    "        with open('dataset/text_partial/' + text_file, 'r') as file:\n",
    "            text = file.read()\n",
    "\n",
    "        text = text.replace('\\n',', ')\n",
    "        text_return = self.text_tokenizer(text, return_tensors=\"pt\")\n",
    "        text_return = torch.squeeze(text_return['input_ids'], 0)\n",
    "\n",
    "        midi_file = MidiFile('dataset/midi_partial/' + self.midi_files[idx])\n",
    "        midi = torch.LongTensor(self.midi_tokenizer(midi_file))\n",
    "        EOS_tensor = torch.LongTensor(music_EOS_token)\n",
    "        midi_return = torch.cat([midi, EOS_tensor], dim = 0)\n",
    "        \n",
    "        return text_return, midi_return\n",
    "\n",
    "\n",
    "class Val_Dataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.text_files = get_filtered_files('dataset/text_partial', ['.ipynb_checkpoints', '.DS_Store'])\n",
    "        self.midi_files = get_filtered_files('dataset/midi_partial', ['.ipynb_checkpoints', '.DS_Store'])\n",
    "        self.text_tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "        self.midi_tokenizer = Octuple(TokenizerConfig(use_programs=True))\n",
    "        \n",
    "        # Calculate the number of files to use for training (90% of the total)\n",
    "        self.val_size = int(0.1 * len(self.midi_files))\n",
    "        train_size = int(0.8 * len(self.midi_files))\n",
    "        val_start_index = train_size\n",
    "        val_end_index = train_size + self.val_size\n",
    "        self.text_files = self.text_files[val_start_index: val_end_index]\n",
    "        self.midi_files = self.midi_files[val_start_index: val_end_index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.midi_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text_file = self.text_files[idx]\n",
    "        with open('dataset/text_partial/' + text_file, 'r') as file:\n",
    "            text = file.read()\n",
    "\n",
    "        text = text.replace('\\n',', ')\n",
    "        text_return = self.text_tokenizer(text, return_tensors=\"pt\")\n",
    "        text_return = torch.squeeze(text_return['input_ids'], 0)\n",
    "\n",
    "        midi_file = MidiFile('dataset/midi_partial/' + self.midi_files[idx])\n",
    "        midi = torch.LongTensor(self.midi_tokenizer(midi_file))\n",
    "        EOS_tensor = torch.LongTensor(music_EOS_token)\n",
    "        midi_return = torch.cat([midi, EOS_tensor], dim = 0)\n",
    "        \n",
    "        return text_return, midi_return\n",
    "\n",
    "class Test_Dataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.text_files = get_filtered_files('dataset/text_partial', ['.ipynb_checkpoints', '.DS_Store'])\n",
    "        self.midi_files = get_filtered_files('dataset/midi_partial', ['.ipynb_checkpoints', '.DS_Store'])\n",
    "        self.text_tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "        self.midi_tokenizer = Octuple(TokenizerConfig(use_programs=True))\n",
    "        \n",
    "        # Calculate the number of files to use for training (90% of the total)\n",
    "        self.test_size = int(0.1 * len(self.midi_files))\n",
    "        self.text_files = self.text_files[-self.test_size:]\n",
    "        self.midi_files = self.midi_files[-self.test_size:]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.midi_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text_file = self.text_files[idx]\n",
    "        with open('dataset/text_partial/' + text_file, 'r') as file:\n",
    "            text = file.read()\n",
    "\n",
    "        text = text.replace('\\n',', ')\n",
    "        text_return = self.text_tokenizer(text, return_tensors=\"pt\")\n",
    "        text_return = torch.squeeze(text_return['input_ids'], 0)\n",
    "\n",
    "        midi_file = MidiFile('dataset/midi_partial/' + self.midi_files[idx])\n",
    "        midi = torch.LongTensor(self.midi_tokenizer(midi_file))\n",
    "        EOS_tensor = torch.LongTensor(music_EOS_token)\n",
    "        midi_return = torch.cat([midi, EOS_tensor], dim = 0)\n",
    "        \n",
    "        return text_return, midi_return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c951665-fde1-49ab-918f-e58a86231815",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    text, music = zip(*data)\n",
    "    text = nn.utils.rnn.pad_sequence(text, batch_first=True)\n",
    "    music = nn.utils.rnn.pad_sequence(music, batch_first=True, padding_value=0)\n",
    "    return text, music\n",
    "        \n",
    "train_data = Train_Dataset()\n",
    "val_data = Val_Dataset()\n",
    "test_data = Test_Dataset()\n",
    "\n",
    "torch.set_printoptions(profile=\"default\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cd2cde3-00e1-4e78-909c-dcf178f035cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[40, 23, 11,  4,  4, 57],\n",
      "        [47, 23, 11,  4,  4, 57],\n",
      "        [52, 23, 11,  4,  4, 57],\n",
      "        ...,\n",
      "        [ 0,  0,  0,  0,  0,  0],\n",
      "        [ 0,  0,  0,  0,  0,  0],\n",
      "        [ 0,  0,  0,  0,  0,  0]])\n"
     ]
    }
   ],
   "source": [
    "#normal version\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=True, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=True, drop_last=True, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(test_data, batch_size=1, shuffle=True, drop_last=True, collate_fn=collate_fn)\n",
    "\n",
    "text, midi = next(iter(train_dataloader))\n",
    "print(midi[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a215875f-68ef-46e0-b5d8-d9c16a99ea12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92, 36, 68, 36, 84, 133] tokens with ('T', 'C') io format(one token stream, multi-voc), without BPE\n",
      "[92, 36, 68, 36, 64, 133] tokens with ('T', 'C') io format(one token stream, multi-voc), without BPE\n",
      "[92, 36, 68, 36, 64, 133] tokens with ('T', 'C') io format(one token stream, multi-voc), without BPE\n"
     ]
    }
   ],
   "source": [
    "# TRAINING\n",
    "text_files  = get_filtered_files('dataset/text_partial', ['.ipynb_checkpoints', '.DS_Store'])\n",
    "midi_files = get_filtered_files('dataset/midi_partial', ['.ipynb_checkpoints', '.DS_Store'])\n",
    "folder_path = \"dataset/midi_partial/\"\n",
    "\n",
    "print(train_data.midi_tokenizer)\n",
    "print(val_data.midi_tokenizer)\n",
    "print(test_data.midi_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "337243e3-6e7a-4193-8338-33f551725adf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92, 36, 68, 36, 325, 133] tokens with ('T', 'C') io format(one token stream, multi-voc), without BPE\n",
      "[92, 36, 68, 36, 325, 133] tokens with ('T', 'C') io format(one token stream, multi-voc), without BPE\n",
      "[92, 36, 68, 36, 325, 133] tokens with ('T', 'C') io format(one token stream, multi-voc), without BPE\n"
     ]
    }
   ],
   "source": [
    "mid = train_data.midi_tokenizer(\"dataset/midi_partial/mmd_99c1fc2ced2ebca9cf8863ad50ac76d7.mid\") #assume this format\n",
    "mid = val_data.midi_tokenizer(\"dataset/midi_partial/mmd_99c1fc2ced2ebca9cf8863ad50ac76d7.mid\")\n",
    "mid = test_data.midi_tokenizer(\"dataset/midi_partial/mmd_99c1fc2ced2ebca9cf8863ad50ac76d7.mid\")\n",
    "\n",
    "print(train_data.midi_tokenizer)\n",
    "print(val_data.midi_tokenizer)\n",
    "print(test_data.midi_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c93fad4-092e-4be6-8cf3-825e479c3bb0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total setup time: 2.8696582317352295\n"
     ]
    }
   ],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    probs = np.exp(logits / temperature) / np.sum(np.exp(logits / temperature))\n",
    "    return probs\n",
    "\n",
    "\n",
    "def weighted_sampling(probs):\n",
    "    probs /= sum(probs)\n",
    "    sorted_probs = np.sort(probs)[::-1]\n",
    "    sorted_index = np.argsort(probs)[::-1]\n",
    "    word = np.random.choice(sorted_index, size=1, p=sorted_probs)[0]\n",
    "    return word\n",
    "\n",
    "\n",
    "# -- nucleus -- #\n",
    "def nucleus(probs, p):\n",
    "    probs /= (sum(probs) + 1e-5)\n",
    "    sorted_probs = np.sort(probs)[::-1]\n",
    "    sorted_index = np.argsort(probs)[::-1]\n",
    "    cusum_sorted_probs = np.cumsum(sorted_probs)\n",
    "    after_threshold = cusum_sorted_probs > p\n",
    "    if sum(after_threshold) > 0:\n",
    "        last_index = np.where(after_threshold)[0][0] + 1\n",
    "        candi_index = sorted_index[:last_index]\n",
    "    else:\n",
    "        candi_index = sorted_index[:]\n",
    "    candi_probs = [probs[i] for i in candi_index]\n",
    "    candi_probs /= sum(candi_probs)\n",
    "    word = np.random.choice(candi_index, size=1, p=candi_probs)[0]\n",
    "    return word\n",
    "\n",
    "\n",
    "def sampling(logit, p=None, t=1.0):\n",
    "    logit = logit.squeeze().cpu().numpy()\n",
    "    probs = softmax_with_temperature(logits=logit, temperature=t)\n",
    "    \n",
    "    if p is not None:\n",
    "        cur_word = nucleus(probs, p=p)\n",
    "    else:\n",
    "        cur_word = weighted_sampling(probs)\n",
    "    return cur_word\n",
    "\n",
    "\n",
    "setup_time = time.time() - start_setup_time\n",
    "print(f\"total setup time: {setup_time}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0224f0b-d234-4f58-a286-9036349e7ee1",
   "metadata": {},
   "source": [
    "# Main section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "523d3923-53db-440f-af78-51262daed5a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "music_size = len(train_data.midi_tokenizer) \n",
    "\n",
    "#FOR EVAL\n",
    "max_generation_length = 1000\n",
    "saved_checkpoint_path = 'autoregressive_transpose_text_to_midi_model.pt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0f23830-7b40-41ff-8de9-4e7136c7eef1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model = 768, dropout: float = 0.1, max_len: int = 5000): #changed from 2000-4000 - 30k\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
    "        \"\"\"\n",
    "        x = x.permute(1, 0, 2)\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        x = self.dropout(x)\n",
    "        x = x.permute(1, 0, 2)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MusicTransformer(nn.Module):\n",
    "    def __init__(self, is_training=True):\n",
    "        super(MusicTransformer, self).__init__()\n",
    "        self.roberta = RobertaModel.from_pretrained(\"roberta-base\").to(device)\n",
    "        self.transformer = TransformerEncoderBuilder.from_kwargs(\n",
    "            n_layers=6, #normally 10...\n",
    "            n_heads=6,\n",
    "            query_dimensions=768,\n",
    "            value_dimensions=128,\n",
    "            feed_forward_dimensions=768,\n",
    "            activation='gelu',\n",
    "            dropout=0.1,\n",
    "            attention_type=\"causal-linear\",\n",
    "        ).get()\n",
    "            \n",
    "        self.postional_encoding = PositionalEncoding()\n",
    "        self.embedding_pitch = nn.Embedding(num_embeddings=92, embedding_dim=128)\n",
    "        self.embedding_velocity = nn.Embedding(num_embeddings=36, embedding_dim=128)\n",
    "        self.embedding_duration = nn.Embedding(num_embeddings=68, embedding_dim=128)\n",
    "        self.embedding_position = nn.Embedding(num_embeddings=36, embedding_dim=128)\n",
    "        self.embedding_bar = nn.Embedding(num_embeddings=len(train_data.midi_tokenizer.vocab[4]), embedding_dim=128)\n",
    "        self.embedding_program = nn.Embedding(num_embeddings=133, embedding_dim=128)\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.dropout = nn.Dropout(p=0.4) # produces different outputs - avoiding different outputs\n",
    "        \n",
    "        self.linear = nn.Linear(768, 256)\n",
    "    \n",
    "        self.pitch_output = nn.Linear(256, 92)\n",
    "        self.velocity_output = nn.Linear(256, 36)\n",
    "        self.duration_output = nn.Linear(256, 68)\n",
    "        self.position_output = nn.Linear(256, 36)\n",
    "        self.bar_output = nn.Linear(256, len(train_data.midi_tokenizer.vocab[4])) # impt cos its variable! - fix this \n",
    "        self.program_output = nn.Linear(256, 133)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, text, midi=None, music=None): \n",
    "        \n",
    "        start_token = torch.full((int(batch_size/ngpus), 1, 6), fill_value=1, dtype=torch.int, device=device) # make it VARIABLE according to batch!!\n",
    "        end_token = torch.full((int(batch_size/ngpus), 1, 6), fill_value=2, dtype=torch.int, device=device)#added this for evaluation\n",
    "\n",
    "        text_embedding = self.roberta(text).pooler_output\n",
    "        text_embedding = torch.unsqueeze(text_embedding, 1)\n",
    "        start_embedding = self.embed(start_token)\n",
    "        \n",
    "\n",
    "        \n",
    "        if midi != None: # change to if is_training\n",
    "            midi_embedding = self.embed(midi[:, :-1, :])  #batch,seq, 6 --> 2, seq, 768\n",
    "            input_tensor = torch.cat((text_embedding, start_embedding, midi_embedding), 1)\n",
    "            pos_embedded_input = self.postional_encoding(input_tensor)\n",
    "            attn_mask = TriangularCausalMask(pos_embedded_input.size(1), device=device) # new\n",
    "            output = self.transformer(pos_embedded_input, attn_mask)[:,1:,:] #add attention for training\n",
    "            \n",
    "        else: #evaluation\n",
    "            if music == None:# for first note?\n",
    "                input_tensor = torch.cat((text_embedding, start_embedding), 1)\n",
    "            else:\n",
    "                music_embedding = self.embed(music)\n",
    "                input_tensor = torch.cat((text_embedding, start_embedding, music_embedding), 1)\n",
    "                \n",
    "            pos_embedded_input = self.postional_encoding(input_tensor) #test\n",
    "            attn_mask = TriangularCausalMask(pos_embedded_input.size(1), device=device) # new\n",
    "            output = self.transformer(pos_embedded_input,attn_mask)[:,1:,:] #no attention\n",
    "            \n",
    "\n",
    "        output = self.linear(output)\n",
    "        \n",
    "        pitch_output = self.dropout(self.pitch_output(output))\n",
    "        velocity_output = self.dropout(self.velocity_output(output))\n",
    "        duration_output = self.dropout(self.duration_output(output))\n",
    "        position_output = self.dropout(self.position_output(output))\n",
    "        bar_output = self.dropout(self.bar_output(output))\n",
    "        program_output = self.dropout(self.program_output(output))\n",
    "        \n",
    "        return pitch_output, velocity_output, duration_output, position_output, bar_output, program_output\n",
    "   \n",
    "    \n",
    "    def embed(self, octuple):\n",
    "        embedded_pitch = self.embedding_pitch(octuple[..., 0])\n",
    "        embedded_velocity = self.embedding_velocity(octuple[..., 1])\n",
    "        embedded_duration = self.embedding_duration(octuple[..., 2])\n",
    "        embedded_position = self.embedding_position(octuple[..., 3])\n",
    "        embedded_bar = self.embedding_bar(octuple[..., 4])\n",
    "        embedded_program = self.embedding_program(octuple[..., 5])\n",
    "     \n",
    "        \n",
    "        embedded_octuple = torch.cat([embedded_pitch, embedded_velocity, embedded_duration,\n",
    "                              embedded_position, embedded_bar, embedded_program], dim=-1)\n",
    "        \n",
    "        return embedded_octuple\n",
    "\n",
    "\n",
    "music_model = MusicTransformer() #this is the training_version\n",
    "\n",
    "music_model = music_model.to(device)\n",
    "for p in music_model.roberta.parameters():\n",
    "    p.requires_grad = False\n",
    "    \n",
    "music_model = DataParallel(music_model, device_ids = [0,1,2,3]) #remove for now... # KEEP TO 0,1.\n",
    "\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss() # cross entropy loss for classification purposes\n",
    "optimizer = torch.optim.Adam(music_model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e2a246-a128-436c-88ef-d861b4dc5b68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ad8c90-8c0b-4d63-9df5-3b94056ab565",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.autograd as autograd\n",
    "import time\n",
    "from torchmetrics.classification import MulticlassAccuracy\n",
    "\n",
    "# accuracy = MulticlassAccuracy(num_classes=max_classes).to(device)\n",
    "accuracy_pitch = MulticlassAccuracy(num_classes=92).to(device)\n",
    "accuracy_velocity = MulticlassAccuracy(num_classes=36).to(device)\n",
    "accuracy_duration = MulticlassAccuracy(num_classes=68).to(device)\n",
    "accuracy_position = MulticlassAccuracy(num_classes=36).to(device)\n",
    "accuracy_bar_train = MulticlassAccuracy(num_classes=len(train_data.midi_tokenizer.vocab[4])).to(device) #change for 1 for train 1 for val!\n",
    "accuracy_bar_val = MulticlassAccuracy(num_classes=len(val_data.midi_tokenizer.vocab[4])).to(device) #change for 1 for train 1 for val!\n",
    "accuracy_program = MulticlassAccuracy(num_classes=133).to(device)\n",
    "\n",
    "music_model.train()\n",
    "num_epochs = 10 # use 20\n",
    "total_batches = len(train_dataloader)\n",
    "best_val_loss = 9999\n",
    "\n",
    "softmax = nn.Softmax(dim=1) #softmax after permute for classification.\n",
    "# dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()  # Record the start time for the epoch\n",
    "    total_loss = 0.0\n",
    "    batch_number = 1\n",
    "    print(\"\\nEpoch: \" + str(epoch+1))\n",
    "    for i, data in enumerate(train_dataloader): #new\n",
    "        start_batch_time = time.time()  # Record the start time for the epoch\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        text, midi = data # new\n",
    "        text, midi = text.to(device), midi.to(device)\n",
    "        # print(midi.shape)\n",
    "        # print(text.shape)\n",
    "        output = music_model(text, midi)\n",
    "        \n",
    "        pitch, velocity, duration, position, bar, program = output\n",
    "        \n",
    "        # print(torch.topk(output[0], 1).indices.shape)\n",
    "        \n",
    "        pitch = pitch.permute(0, 2, 1)  # [4, seq, 92] --> [4, 92, seq]\n",
    "        velocity = velocity.permute(0, 2, 1)\n",
    "        duration = duration.permute(0, 2, 1)\n",
    "        position = position.permute(0, 2, 1)\n",
    "        bar = bar.permute(0, 2, 1)\n",
    "        program = program.permute(0, 2, 1)\n",
    "        \n",
    "        # print(torch.topk(pitch, 1).indices.shape)\n",
    "        loss_pitch = criterion(pitch, midi[..., 0])\n",
    "        loss_velocity = criterion(velocity, midi[..., 1])\n",
    "        loss_duration = criterion(duration, midi[..., 2])\n",
    "        loss_position = criterion(position, midi[..., 3])\n",
    "        loss_bar = criterion(bar, midi[..., 4])\n",
    "        loss_program = criterion(program, midi[..., 5])\n",
    "\n",
    "        total_loss = loss_pitch + loss_velocity + loss_duration + loss_position + loss_bar + loss_program\n",
    "        total_average_loss = total_loss / 6\n",
    "        total_average_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_time = time.time() - start_batch_time\n",
    "        \n",
    "\n",
    "        #upkeep\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Batch [{batch_number}/{total_batches}] took {batch_time:.2f} seconds, Average Loss: {total_average_loss:.4f}, Length: {midi.shape}')\n",
    "        batch_number += 1\n",
    "  \n",
    "        # #validation\n",
    "        if i % 8 == 0:\n",
    "\n",
    "            val_start_time = time.time()\n",
    "            val_text, val_midi = next(iter(val_dataloader))\n",
    "            \n",
    "            val_text, val_midi = val_text.to(device), val_midi.to(device)\n",
    "\n",
    "            #running of model!                       \n",
    "            val_octuple_output = music_model(val_text, val_midi)\n",
    "            val_pitch, val_velocity, val_duration, val_position, val_bar, val_program = val_octuple_output\n",
    "            \n",
    "            val_pitch = val_pitch.permute(0, 2, 1)\n",
    "            val_velocity = val_velocity.permute(0, 2, 1)\n",
    "            val_duration = val_duration.permute(0, 2, 1)\n",
    "            val_position = val_position.permute(0, 2, 1)\n",
    "            val_bar = val_bar.permute(0, 2, 1)\n",
    "            val_program = val_program.permute(0, 2, 1)\n",
    "\n",
    "\n",
    "            val_loss_pitch = criterion(val_pitch, val_midi[..., 0])\n",
    "            val_loss_velocity = criterion(val_velocity, val_midi[..., 1])\n",
    "            val_loss_duration = criterion(val_duration, val_midi[..., 2])\n",
    "            val_loss_position = criterion(val_position, val_midi[..., 3])\n",
    "            val_loss_bar = criterion(val_bar, val_midi[..., 4])\n",
    "            val_loss_program = criterion(val_program, val_midi[..., 5])\n",
    "            \n",
    "            \n",
    "            pitch_accuracy = accuracy_pitch(val_pitch, val_midi[..., 0])\n",
    "            velocity_accuracy = accuracy_velocity(val_velocity, val_midi[..., 1])\n",
    "            duration_accuracy = accuracy_duration(val_duration, val_midi[..., 2])\n",
    "            position_accuracy = accuracy_position(val_position, val_midi[..., 3])\n",
    "            bar_accuracy = accuracy_bar_train(val_bar, val_midi[..., 4])\n",
    "            program_accuracy = accuracy_program(val_program, val_midi[..., 5])\n",
    "\n",
    "            print(f'* Accuracy | Pitch: [{pitch_accuracy.item():.4f}], Velocity: [{velocity_accuracy.item():.4f}], Duration: [{duration_accuracy.item():.4f}], Position: [{position_accuracy.item():.4f}], Bar: [{bar_accuracy.item():.4f}], Program: [{program_accuracy.item():.4f}]')\n",
    "        \n",
    "            val_total_loss = val_loss_pitch + val_loss_velocity + val_loss_duration + val_loss_position + val_loss_bar + val_loss_program\n",
    "            val_total_average_loss = val_total_loss / 6\n",
    "            \n",
    "            if val_total_average_loss < best_val_loss:\n",
    "                best_val_loss = val_total_average_loss\n",
    "                torch.save(music_model.state_dict(), saved_checkpoint_path)\n",
    "            val_time = time.time() - val_start_time\n",
    "            print(f'* Epoch [{epoch + 1}/{num_epochs}], Validation took {val_time:.2f} seconds, Validation Loss: {val_total_average_loss:.4f}, Best Validation Loss: {best_val_loss:.4f}')\n",
    "    \n",
    "\n",
    "    epoch_time = time.time() - start_time\n",
    "    print(f\"Epoch {epoch+1} took {epoch_time:.2f} seconds\")\n",
    "    \n",
    "    for g in optimizer.param_groups:\n",
    "        g['lr'] *= 0.8 #was 0.7 then 0.6 most of the time\n",
    "# print(torch.topk(output[0], 1).indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2bff8a-b96a-43b2-aa39-2a22e1a4102e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67b0a51a-3937-4ff5-bfb6-27e262616a90",
   "metadata": {},
   "source": [
    "# Saving and evaluating - check for checkpoint error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d9c2e67-75c4-4f5e-8e6a-de5b86a5d751",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "def load_saved_model(saved_checkpoint_path):\n",
    "    device = get_device()\n",
    "    saved_transformer_model = MusicTransformer(is_training=False) # for evaluation\n",
    "    device = torch.device(device) \n",
    "\n",
    "    print(saved_checkpoint_path)\n",
    "    saved_transformer_model = saved_transformer_model.to(device)\n",
    "    state_dict = torch.load(saved_checkpoint_path)\n",
    "\n",
    "    # Load the state dictionary into the model\n",
    "    new_state_dict = OrderedDict()\n",
    "    for key, value in state_dict.items():\n",
    "        name = key[7:]  # remove the \"module.\" prefix\n",
    "        new_state_dict[name] = value\n",
    "\n",
    "    # Load the state dictionary into the model\n",
    "    saved_transformer_model.load_state_dict(new_state_dict, strict=False)\n",
    "    \n",
    "    return saved_transformer_model\n",
    "\n",
    "\n",
    "def prepare_text_input(input_string):\n",
    "    text_tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "    text_input = text_tokenizer(input_string, return_tensors=\"pt\")\n",
    "    text_input = torch.squeeze(text_input['input_ids'], 0)\n",
    "    text_input = text_input.reshape((1, -1))\n",
    "    text_input = text_input.to(device)\n",
    "    \n",
    "    return text_input\n",
    "\n",
    "\n",
    "\n",
    "# the format of the output vs the midi quite different.\n",
    "# more for batchsize of 1 for now!!\n",
    "def shape_output_to_tensor(output):\n",
    "    \n",
    "    pitch, velocity, duration, position, bar, program = output # pitch = batch, seq, class\n",
    "    # print(pitch)\n",
    "    \n",
    "    if batch_size/ngpus > 1:\n",
    "        pitch = pitch[-1,:,:].unsqueeze(0)\n",
    "        velocity = velocity[-1,:,:].unsqueeze(0)\n",
    "        duration = duration[-1,:,:].unsqueeze(0)\n",
    "        position = position[-1,:,:].unsqueeze(0)\n",
    "        bar = bar[-1,:,:].unsqueeze(0)\n",
    "        program = program[-1,:,:].unsqueeze(0)\n",
    "    \n",
    "\n",
    "    #most updated hyperparams\n",
    "    cur_pitch = sampling(pitch[:,-1,:], t=1.2, p=0.5) \n",
    "    cur_velocity = sampling(velocity[:,-1,:], t=2)\n",
    "    cur_duration = sampling(duration[:,-1,:], t=1.25, p=0.5)\n",
    "    cur_position = sampling(position[:,-1,:], t=1.5, p=0.5)  \n",
    "    cur_bar = sampling(bar[:,-1,:], t=0.6)\n",
    "    cur_program = sampling(program[:,-1,:], t=1.25, p=0.45)\n",
    "    \n",
    "    cur_bar = torch.topk(bar[:,-1,:], 1).indices\n",
    "    cur_bar = cur_bar.to(torch.device(\"cpu\")).numpy().astype(np.int64).item() \n",
    "\n",
    "    next_arr = np.array([\n",
    "            cur_pitch,\n",
    "            cur_velocity,\n",
    "            cur_duration,\n",
    "            cur_position,\n",
    "            cur_bar,\n",
    "            cur_program,\n",
    "            ])      \n",
    "    \n",
    "        \n",
    "    return torch.tensor(next_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25040b2-5018-43ee-b09c-24c48b03f83f",
   "metadata": {},
   "source": [
    "### Evaluation Code - Autoregressive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b287857-407c-4edb-afcd-3fa528a74fb2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autoregressive_22feb_transpose_text_to_midi_model.pt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# input_string = \"slow sad song, with a long flowing melody line\"\n",
    "# input_string = \"Classical love song, upbeat tempo, and complex harmony.\"\n",
    "input_string = \"Dramatic film score, with romantic melodies\"\n",
    "\n",
    "saved_checkpoint_path_eval = 'autoregressive_transpose_text_to_midi_model.pt'\n",
    "saved_transformer_model = load_saved_model(saved_checkpoint_path_eval)\n",
    "text_input = prepare_text_input(input_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40d7169e-5415-4bf4-8706-75262b4deff2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 6])\n",
      "torch.Size([1, 51, 6])\n",
      "torch.Size([1, 101, 6])\n",
      "torch.Size([1, 151, 6])\n",
      "torch.Size([1, 201, 6])\n",
      "torch.Size([1, 251, 6])\n",
      "torch.Size([1, 301, 6])\n",
      "torch.Size([1, 351, 6])\n",
      "torch.Size([1, 401, 6])\n",
      "torch.Size([1, 451, 6])\n",
      "torch.Size([1, 501, 6])\n",
      "torch.Size([1, 551, 6])\n",
      "torch.Size([1, 601, 6])\n",
      "torch.Size([1, 651, 6])\n",
      "torch.Size([1, 701, 6])\n",
      "torch.Size([1, 751, 6])\n",
      "torch.Size([1, 800, 6])\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "music_model.eval()\n",
    "saved_transformer_model.eval()\n",
    "\n",
    "max_generation_length = 800\n",
    "\n",
    "with torch.no_grad():\n",
    "    if batch_size / ngpus == 2: # alternates between batch size of 2 for the model, and 1 for the output\n",
    "        duplicated_text_input = np.tile(text_input.to(torch.device(\"cpu\")), (2, 1))\n",
    "        duplicated_text_input = torch.tensor(duplicated_text_input, device=device)\n",
    "        step_output = saved_transformer_model(text=duplicated_text_input) \n",
    "        \n",
    "        eval_output = shape_output_to_tensor(step_output).to(device) #convert 2,1,96 etc to 1,1,96\n",
    "        midi_output= eval_output.unsqueeze(0).unsqueeze(0)\n",
    "        duplicated_midi_output = np.tile(midi_output.to(torch.device(\"cpu\")), (2, 1, 1))\n",
    "        duplicated_midi_output = torch.tensor(duplicated_midi_output, device=device) #convert back to 2 batch size for the model\n",
    "        \n",
    "        for i in range(max_generation_length-1):\n",
    "            step_output = saved_transformer_model(text=duplicated_text_input, music = duplicated_midi_output)\n",
    "            eval_output = shape_output_to_tensor(step_output).to(device)\n",
    "                \n",
    "            if i %50 == 0:        \n",
    "                print(midi_output.shape)\n",
    "            \n",
    "            midi_output= torch.cat((midi_output, eval_output.unsqueeze(0).unsqueeze(0)),dim=1)\n",
    "            duplicated_midi_output = np.tile(midi_output.to(torch.device(\"cpu\")), (2, 1, 1))\n",
    "            duplicated_midi_output = torch.tensor(duplicated_midi_output, device=device)\n",
    "            \n",
    "            \n",
    "    \n",
    "    \n",
    "    if batch_size / ngpus == 1: #when its just 4\n",
    "        step_output = saved_transformer_model(text=text_input)      #tuple of 6 : 1,1,92\n",
    "        eval_output = shape_output_to_tensor(step_output).to(device) #dimension = [6]\n",
    "        midi_output= eval_output.unsqueeze(0).unsqueeze(0)\n",
    "        \n",
    "        for i in range(max_generation_length-1):\n",
    "            step_output = saved_transformer_model(text=text_input, music = midi_output) #convert to tensor\n",
    "            eval_output = shape_output_to_tensor(step_output).to(device)\n",
    "            \n",
    "            if i %50 == 0:        \n",
    "                print(midi_output.shape)\n",
    "            \n",
    "            midi_output= torch.cat((midi_output, eval_output.unsqueeze(0).unsqueeze(0)),dim=1)\n",
    "    \n",
    "    print(midi_output.shape)\n",
    "    print(\"done\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "395a7c02-f150-44c9-95c2-1e979dd2d374",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 20,  28,  27,   4,   4, 100],\n",
      "         [  7,  13,  67,   4,   4,  89],\n",
      "         [ 43,  24,  27,   4,   4,  25],\n",
      "         [ 55,  26,  27,   4,   4,  73],\n",
      "         [ 67,  25,  11,   4,   4,  57],\n",
      "         [ 55,  28,  50,  12,   4,  57],\n",
      "         [ 59,  16,  27,  20,   4,  73],\n",
      "         [ 38,  31,  27,  20,   4,  47],\n",
      "         [ 59,  28,  27,  20,   4,  59],\n",
      "         [ 35,  23,  27,  20,   4,  65],\n",
      "         [ 43,  20,  27,  20,   4,  19],\n",
      "         [ 52,  24,  27,  20,   4,  73],\n",
      "         [ 55,  16,  27,  28,   4, 114],\n",
      "         [ 59,  17,  27,  28,   4,  40],\n",
      "         [ 38,  28,  27,  28,   4,  73],\n",
      "         [ 57,  20,  27,  28,   4,   5],\n",
      "         [ 59,  21,  27,  28,   4,  51],\n",
      "         [ 40,  20,  19,  28,   4,  24],\n",
      "         [ 57,  21,  19,  28,   4,  20],\n",
      "         [ 59,  13,  27,  32,   4,  31],\n",
      "         [ 31,  25,  27,  32,   5,  73],\n",
      "         [ 40,  23,  27,  32,   5,  53],\n",
      "         [ 52,  23,  27,  32,   5,  73],\n",
      "         [ 31,  29,  11,   4,   5,   5],\n",
      "         [ 43,  12,  27,   4,   5,  76],\n",
      "         [ 55,  24,  27,  12,   5, 131],\n",
      "         [ 36,  22,  27,  12,   5,  73],\n",
      "         [ 48,  25,  27,  12,   5,  73],\n",
      "         [ 52,  29,  27,   4,   5,  73],\n",
      "         [ 35,  31,  27,   4,   5,  73],\n",
      "         [ 38,  30,  27,   4,   5,  51],\n",
      "         [ 47,  34,  27,   4,   5,  67],\n",
      "         [ 50,  31,  27,   8,   5,  14],\n",
      "         [ 38,  24,  27,  12,   5,  78],\n",
      "         [ 43,  31,  27,  12,   5,  93],\n",
      "         [ 52,  10,  27,  12,   5,  73],\n",
      "         [ 54,  18,  27,  12,   5, 118],\n",
      "         [ 55,  21,  27,  12,   5,  57],\n",
      "         [ 59,  15,  27,  12,   5,  61],\n",
      "         [ 47,  16,  27,  20,   5,  65],\n",
      "         [ 50,  18,  27,  20,   5,  61],\n",
      "         [ 54,  14,  27,  20,   5,  45],\n",
      "         [ 57,  14,  27,  20,   5,  40],\n",
      "         [ 40,  17,  27,  20,   5,   9],\n",
      "         [ 50,  17,  27,  20,   5,  59],\n",
      "         [ 54,  16,  27,  20,   5,  53],\n",
      "         [ 57,  21,  27,  28,   5,  41],\n",
      "         [ 38,  19,  11,   4,   5, 104],\n",
      "         [ 43,  18,  27,   4,   5,  16],\n",
      "         [ 43,  16,  27,   4,   5,  11],\n",
      "         [ 47,  27,  27,   4,   5,  73],\n",
      "         [ 52,   5,  27,   4,   5, 103],\n",
      "         [ 38,  31,  27,   4,   5,  47],\n",
      "         [ 48,  24,  27,   4,   5,  86],\n",
      "         [ 57,  11,  27,  28,   5,  48],\n",
      "         [ 33,  21,  11,  28,   5,  78],\n",
      "         [ 50,  15,  19,  28,   5,  29],\n",
      "         [ 52,  16,  19,   4,   5,  31],\n",
      "         [ 31,  35,  27,  16,   5,  37],\n",
      "         [ 47,  26,  27,  12,   5,  57],\n",
      "         [ 47,  20,  27,  12,   5,  79],\n",
      "         [ 48,  12,  27,  14,   5,  57],\n",
      "         [ 55,  16,  27,  16,   5,  57],\n",
      "         [ 43,  15,  27,  16,   5, 117],\n",
      "         [ 55,   8,  27,  16,   5,  57],\n",
      "         [ 55,  18,  27,  20,   5, 126],\n",
      "         [ 59,  11,  27,  28,   5,   4],\n",
      "         [ 38,  28,  27,   4,   5,  73],\n",
      "         [ 45,   9,  27,   4,   5,  59],\n",
      "         [ 48,  19,  27,   4,   5,  21],\n",
      "         [ 52,   4,  27,   4,   5,  65],\n",
      "         [ 45,  15,  27,  13,   5,  40],\n",
      "         [ 52,   4,  27,  13,   5,  62],\n",
      "         [ 55,  20,  27,  20,   5,  73],\n",
      "         [ 57,  15,  27,  12,   5,  11],\n",
      "         [ 43,  16,  27,  12,   5,  53],\n",
      "         [ 47,  16,  27,  24,   5, 126],\n",
      "         [ 50,   9,  27,  24,   5,  53],\n",
      "         [ 54,  31,  27,  24,   5,  28],\n",
      "         [ 55,  30,  27,  24,   5,   5],\n",
      "         [ 59,  31,  27,  24,   5,  61],\n",
      "         [ 31,  17,  27,  24,   5,  30],\n",
      "         [ 50,  16,  27,  26,   5,  24],\n",
      "         [ 38,  27,  27,  28,   5,  93],\n",
      "         [ 43,  26,  27,  28,   5,   2],\n",
      "         [ 55,  12,  27,  28,   5,  24],\n",
      "         [ 50,  11,  27,  28,   5,  32],\n",
      "         [ 48,  18,  27,  28,   5,  28],\n",
      "         [ 52,  18,  27,  28,   5,   8],\n",
      "         [ 50,  10,  27,   4,   5,   5],\n",
      "         [ 54,  19,  27,   4,   5,  57],\n",
      "         [ 52,  15,  27,   4,   5, 111],\n",
      "         [ 57,  18,  27,   4,   5, 104],\n",
      "         [ 47,  13,  27,   4,   5,  65],\n",
      "         [ 50,  33,  27,   4,   5, 100],\n",
      "         [ 48,  29,  27,   4,   5,  46],\n",
      "         [ 50,  30,  27,   4,   5,  76],\n",
      "         [ 55,  15,  27,   4,   5,  73],\n",
      "         [ 48,  27,  27,   4,   5,   4],\n",
      "         [ 55,  18,  27,  12,   5,  73],\n",
      "         [ 52,   8,  27,  12,   5,   4],\n",
      "         [ 47,  10,  27,  12,   5,  16],\n",
      "         [ 55,  12,  27,  12,   5,   6],\n",
      "         [ 48,  26,  27,  20,   5,  51],\n",
      "         [ 57,  35,  27,  20,   5,  65],\n",
      "         [ 43,   7,  27,  20,   5,  16],\n",
      "         [ 47,  12,  27,  20,   5, 117],\n",
      "         [ 55,  16,  27,  20,   5,  77],\n",
      "         [ 57,   6,  27,  20,   5,  73],\n",
      "         [ 47,  20,  27,  28,   5,  73],\n",
      "         [ 52,  30,  27,  28,   5,  30],\n",
      "         [ 54,  14,  27,  28,   5,  16],\n",
      "         [ 47,   9,  27,  28,   5,  21],\n",
      "         [ 54,  19,  27,  28,   5,  79],\n",
      "         [ 59,  31,  27,  28,   5,  93],\n",
      "         [ 38,  34,  27,  28,   5,  87],\n",
      "         [ 47,  17,  27,  20,   5,  21],\n",
      "         [ 47,  27,  27,  20,   5, 104],\n",
      "         [ 50,  26,  27,  20,   5,  53],\n",
      "         [ 43,  16,  27,  20,   5,  48],\n",
      "         [ 52,  30,  27,  20,   5,  37],\n",
      "         [ 45,  18,  27,  20,   5,  16],\n",
      "         [ 50,  23,  27,  16,   5,  16],\n",
      "         [ 54,  13,  27,  16,   5,  53],\n",
      "         [ 54,  10,  27,  17,   5,  28],\n",
      "         [ 57,  14,  27,  12,   5, 104],\n",
      "         [ 55,   6,  27,   4,   5,  16],\n",
      "         [ 35,  32,  27,   4,   5,  55],\n",
      "         [ 40,  22,  27,   4,   5,   8],\n",
      "         [ 52,  17,  27,   4,   5,  16],\n",
      "         [ 55,  28,  27,   4,   5,  51],\n",
      "         [ 38,  27,  27,  12,   5,   7],\n",
      "         [ 52,  17,  27,  12,   5,  75],\n",
      "         [ 50,   4,  27,  12,   5,  73],\n",
      "         [ 48,  17,  27,  12,   5,  57],\n",
      "         [ 55,  10,  27,  12,   5,  57],\n",
      "         [ 47,  11,  27,  12,   5,  57],\n",
      "         [ 47,  13,  27,  12,   5,  24],\n",
      "         [ 59,  28,  27,  12,   5,  76],\n",
      "         [ 38,  33,  27,  16,   5,  21],\n",
      "         [ 55,  27,  27,  20,   5,  21],\n",
      "         [ 52,  25,  27,  28,   5,  79],\n",
      "         [ 48,   4,  27,  28,   5,  73],\n",
      "         [ 43,  17,  27,  31,   5,  41],\n",
      "         [ 47,  17,  27,  33,   5, 104],\n",
      "         [ 47,  29,  27,  12,   5,  15],\n",
      "         [ 47,  10,  27,  12,   5,  94],\n",
      "         [ 59,  21,  27,  28,   5,  84],\n",
      "         [ 52,  20,  27,  27,   5,  16],\n",
      "         [ 52,  14,  27,  28,   5,  59],\n",
      "         [ 47,   8,  27,  29,   5,  57],\n",
      "         [ 50,  22,  27,  29,   5,  57],\n",
      "         [ 48,  23,  27,  29,   5,  46],\n",
      "         [ 48,   2,  27,  20,   5,  74],\n",
      "         [ 52,  26,  27,  20,   5,  25],\n",
      "         [ 54,  10,  27,  20,   5,  59],\n",
      "         [ 43,  17,  27,  20,   5,  31],\n",
      "         [ 52,  11,  27,  20,   5,  15],\n",
      "         [ 48,   7,  27,  25,   5,  16],\n",
      "         [ 50,  11,  27,  29,   5, 128],\n",
      "         [ 54,  28,  27,  12,   5,  40],\n",
      "         [ 48,  16,  27,  12,   5,  59],\n",
      "         [ 52,  13,  27,  12,   5,  55],\n",
      "         [ 45,  33,  27,  12,   5,   9],\n",
      "         [ 48,  35,  27,  12,   5,  57],\n",
      "         [ 48,  33,  27,  16,   5,  76],\n",
      "         [ 52,  19,  27,  16,   5,  59],\n",
      "         [ 45,  31,  27,  18,   5,  73],\n",
      "         [ 52,  17,  27,  19,   5, 106],\n",
      "         [ 57,  14,  27,  30,   5,   9],\n",
      "         [ 45,  33,  27,  30,   5,   8],\n",
      "         [ 52,  24,  27,  34,   5,  79],\n",
      "         [ 50,  23,  27,  23,   5,   9],\n",
      "         [ 45,  16,  27,  25,   5, 100],\n",
      "         [ 45,  35,  27,  25,   5,   4],\n",
      "         [ 48,  27,  27,  25,   5,  79],\n",
      "         [ 47,   6,  27,  25,   5,  59],\n",
      "         [ 50,  18,  27,  26,   5, 104],\n",
      "         [ 52,  25,  27,  23,   5,  15],\n",
      "         [ 55,  31,  27,   4,   5,  37],\n",
      "         [ 60,   9,  27,   4,   5,  78],\n",
      "         [ 48,  21,  27,   4,   5,  57],\n",
      "         [ 43,  17,  27,   4,   5,  56],\n",
      "         [ 47,   5,  27,   4,   5,  87],\n",
      "         [ 48,  28,  27,   4,   5,  25],\n",
      "         [ 48,  20,  27,   4,   5,  94],\n",
      "         [ 52,   9,  27,   4,   5,  57],\n",
      "         [ 47,  25,  27,   4,   5,  70],\n",
      "         [ 31,  16,  27,   4,   5,  29],\n",
      "         [ 35,  20,  27,   4,   5,  48],\n",
      "         [ 47,  19,  27,   4,   5,  40],\n",
      "         [ 52,   9,  27,   7,   5,  31],\n",
      "         [ 48,  18,  27,   7,   5,  96],\n",
      "         [ 52,   4,  27,   7,   5, 104],\n",
      "         [ 50,  29,  27,   8,   5,  55],\n",
      "         [ 52,  31,  27,   8,   5,  48],\n",
      "         [ 36,  12,  27,  12,   5,  75],\n",
      "         [ 52,  18,  27,  14,   5, 104],\n",
      "         [ 36,   9,  27,  16,   5,  70],\n",
      "         [ 52,  31,  27,  20,   5,  97],\n",
      "         [ 55,  27,  27,  20,   5,  61],\n",
      "         [ 54,  12,  27,  20,   5,  40],\n",
      "         [ 45,   9,  27,  20,   5,  53],\n",
      "         [ 48,  18,  27,  20,   5,  57],\n",
      "         [ 52,  22,  27,  23,   5,  15],\n",
      "         [ 45,  10,  27,  24,   5,  59],\n",
      "         [ 50,  25,  27,  28,   5,  75],\n",
      "         [ 43,  22,  27,  28,   5,  58],\n",
      "         [ 55,  31,  27,  28,   5, 104],\n",
      "         [ 57,  21,  27,  28,   5,  59],\n",
      "         [ 54,  35,  27,  28,   5,  55],\n",
      "         [ 50,   3,  27,  28,   5,  37],\n",
      "         [ 55,  16,  27,  28,   5,  19],\n",
      "         [ 48,  31,  27,  28,   5,  70],\n",
      "         [ 52,  28,  27,   7,   5,  70],\n",
      "         [ 55,  17,  27,  16,   5, 123],\n",
      "         [ 50,  15,  27,  16,   5,  41],\n",
      "         [ 43,  33,  27,  20,   5,  40],\n",
      "         [ 47,  15,  27,  20,   5,  20],\n",
      "         [ 48,  35,  27,  20,   5,  62],\n",
      "         [ 47,   9,  27,  20,   5,  12],\n",
      "         [ 52,   9,  27,  20,   5,  57],\n",
      "         [ 54,  30,  27,  20,   5,  25],\n",
      "         [ 59,  20,  27,  20,   5,   5],\n",
      "         [ 43,   5,  27,  20,   5,  62],\n",
      "         [ 52,  28,  27,  20,   5,  32],\n",
      "         [ 50,  19,  27,  20,   5,  10],\n",
      "         [ 55,   9,  27,  20,   5,  16],\n",
      "         [ 59,   9,  27,  23,   5,  12],\n",
      "         [ 50,  20,  27,  28,   5,  45],\n",
      "         [ 55,  28,  27,  28,   5,  97],\n",
      "         [ 67,  13,  27,   4,   5,  16],\n",
      "         [ 38,  19,  27,   4,   5,  70],\n",
      "         [ 41,  31,  27,   4,   5,  51],\n",
      "         [ 50,  31,  27,   4,   5,  24],\n",
      "         [ 53,  12,  27,   4,   5,  24],\n",
      "         [ 48,  25,  27,  34,   5,  32],\n",
      "         [ 55,  24,  27,  34,   5, 105],\n",
      "         [ 43,  29,  27,   4,   5, 106],\n",
      "         [ 47,   9,  27,   4,   5,  97],\n",
      "         [ 36,  16,  27,   4,   5,  76],\n",
      "         [ 48,  10,  27,   4,   5,  59],\n",
      "         [ 57,  20,  27,   4,   5,  62],\n",
      "         [ 48,  27,  27,   4,   5, 104],\n",
      "         [ 36,  15,  27,   4,   5, 100],\n",
      "         [ 47,  17,  27,   4,   5,  45],\n",
      "         [ 48,  28,  27,   4,   5,  45],\n",
      "         [ 57,   2,  27,   7,   5,  16],\n",
      "         [ 60,  16,  27,   8,   5,   4],\n",
      "         [ 60,  23,  27,  10,   5,  29],\n",
      "         [ 55,  15,  27,  12,   5,  15],\n",
      "         [ 43,  31,  27,  12,   5, 112],\n",
      "         [ 48,  25,  27,  12,   5,  30],\n",
      "         [ 52,  27,  27,  12,   5,  30],\n",
      "         [ 36,  35,  27,  12,   5,  51],\n",
      "         [ 47,  22,  27,  12,   5,  73],\n",
      "         [ 43,  15,  27,  12,   5, 111],\n",
      "         [ 50,  12,  27,  12,   5,  21],\n",
      "         [ 59,  31,  27,  12,   5, 112],\n",
      "         [ 47,  33,  27,  28,   5,  70],\n",
      "         [ 52,  15,  27,  28,   5,  11],\n",
      "         [ 55,  35,  27,  28,   5,  47],\n",
      "         [ 52,  29,  27,  28,   5,  40],\n",
      "         [ 55,  32,  27,  28,   5,  15],\n",
      "         [ 52,  23,  27,  30,   5,  11],\n",
      "         [ 57,  29,  27,  34,   5,  75],\n",
      "         [ 45,  14,  27,  11,   5, 122],\n",
      "         [ 50,  17,  27,  10,   5,  96],\n",
      "         [ 55,  14,  27,  20,   5,  31],\n",
      "         [ 64,  34,  27,  27,   5,  59],\n",
      "         [ 43,  30,  27,  27,   5,  59],\n",
      "         [ 48,  19,  27,  34,   5,  59],\n",
      "         [ 47,  19,  27,  34,   5,  59],\n",
      "         [ 52,  29,  27,  34,   5, 104],\n",
      "         [ 43,  17,  27,   4,   5,  37],\n",
      "         [ 48,  34,  27,   4,   5,  57],\n",
      "         [ 36,  11,  27,   4,   5,  57],\n",
      "         [ 55,   5,  27,   4,   5,  59],\n",
      "         [ 52,  26,  27,   7,   5,  57],\n",
      "         [ 55,  16,  27,   7,   5,  10],\n",
      "         [ 59,  22,  27,   7,   5,  54],\n",
      "         [ 57,  21,  27,   1,   5,  16],\n",
      "         [ 47,  27,  27,  24,   5,  26],\n",
      "         [ 55,  35,  27,  24,   5,  74],\n",
      "         [ 60,  25,  27,  23,   5,   2],\n",
      "         [ 40,  28,  27,   9,   5,  93],\n",
      "         [ 55,  28,  27,   7,   5,  16],\n",
      "         [ 55,  31,  27,  10,   5,  65],\n",
      "         [ 60,  10,  27,  14,   5,  74],\n",
      "         [ 48,   9,  27,  17,   5,  15],\n",
      "         [ 60,  28,  27,  17,   5, 103],\n",
      "         [ 48,  32,  27,  19,   5,  65],\n",
      "         [ 60,   2,  27,  17,   5, 104],\n",
      "         [ 43,  28,  27,  20,   5, 104],\n",
      "         [ 48,  10,  27,  20,   5, 124],\n",
      "         [ 47,  19,  27,  20,   5,  58],\n",
      "         [ 52,  11,  27,  20,   5,  21],\n",
      "         [ 60,  31,  27,  20,   5,  16],\n",
      "         [ 64,   8,  27,  20,   5,  30],\n",
      "         [ 52,  10,  27,  20,   5,  21],\n",
      "         [ 52,   5,  27,  20,   5,  57],\n",
      "         [ 55,  16,  27,  20,   5,  57],\n",
      "         [ 50,  23,  27,  20,   5,   8],\n",
      "         [ 43,  24,  27,  20,   5,  70],\n",
      "         [ 50,  21,  27,  20,   5,  74],\n",
      "         [ 36,   8,  27,  20,   5,  59],\n",
      "         [ 55,   7,  27,  20,   5,  73],\n",
      "         [ 57,  28,  27,  20,   5,  62],\n",
      "         [ 59,  30,  27,  20,   5,   8],\n",
      "         [ 62,  27,  27,  20,   5,  31],\n",
      "         [ 50,  28,  27,  20,   5,  16],\n",
      "         [ 43,  24,  27,  20,   5,  57],\n",
      "         [ 47,  12,  27,  20,   5,  57],\n",
      "         [ 50,  11,  27,  20,   5,  15],\n",
      "         [ 52,  15,  27,  10,   5,  81],\n",
      "         [ 50,  14,  27,  16,   5,   2],\n",
      "         [ 36,  35,  27,  16,   5,  65],\n",
      "         [ 52,   4,  27,  20,   5,  62],\n",
      "         [ 48,  18,  27,  20,   5,   9],\n",
      "         [ 52,   1,  27,  20,   5,   6],\n",
      "         [ 36,  16,  27,  20,   5,  84],\n",
      "         [ 50,  34,  27,  20,   5,  94],\n",
      "         [ 54,  32,  27,  20,   5,  19],\n",
      "         [ 48,   8,  27,  20,   5,  85],\n",
      "         [ 52,  22,  27,  20,   5,  76],\n",
      "         [ 36,  10,  27,  20,   5,  59],\n",
      "         [ 50,  13,  27,  20,   5,  59],\n",
      "         [ 55,  31,  27,  20,   5, 104],\n",
      "         [ 43,  26,  27,  20,   5,  30],\n",
      "         [ 55,  13,  27,  20,   5, 110],\n",
      "         [ 48,  13,  27,  20,   5,  74],\n",
      "         [ 52,  29,  27,  20,   5,  15],\n",
      "         [ 48,  23,  27,  20,   5,  57],\n",
      "         [ 48,  32,  27,  20,   5,  93],\n",
      "         [ 48,  34,  27,  20,   5, 115],\n",
      "         [ 50,  10,  27,  20,   5,  61],\n",
      "         [ 59,  21,  27,  20,   5,  16],\n",
      "         [ 43,  11,  27,  20,   5,  85],\n",
      "         [ 50,  35,  27,  20,   5,  51],\n",
      "         [ 59,  10,  27,  20,   5,  48],\n",
      "         [ 45,   2,  27,   4,   5,  57],\n",
      "         [ 47,  23,  27,   4,   5,  21],\n",
      "         [ 52,   1,  27,   4,   5,   9],\n",
      "         [ 55,  27,  27,  12,   5, 104],\n",
      "         [ 36,  11,  27,  12,   5,  31],\n",
      "         [ 36,  13,  27,  28,   5,  21],\n",
      "         [ 52,  13,  27,  28,   5, 110],\n",
      "         [ 48,  25,  27,  28,   5,  55],\n",
      "         [ 52,   9,  27,  28,   5,  55],\n",
      "         [ 36,  31,  27,  24,   5, 105],\n",
      "         [ 47,  18,  27,  20,   5,   9],\n",
      "         [ 43,   9,  27,  20,   5, 113],\n",
      "         [ 48,  15,  27,  20,   5,  37],\n",
      "         [ 52,  30,  27,  23,   5,  93],\n",
      "         [ 43,  25,  27,  34,   5,  67],\n",
      "         [ 48,  21,  27,  22,   5,  70],\n",
      "         [ 52,  21,  27,  30,   5,  30],\n",
      "         [ 55,  16,  27,  10,   5,  89],\n",
      "         [ 59,  17,  27,  12,   5,  16],\n",
      "         [ 55,  34,  27,  12,   5,  64],\n",
      "         [ 57,  19,  27,  12,   5,  51],\n",
      "         [ 54,  19,  27,  12,   5,  73],\n",
      "         [ 55,  19,  27,  12,   5,  16],\n",
      "         [ 60,  18,  27,  12,   5, 100],\n",
      "         [ 59,  32,  27,  12,   5, 105],\n",
      "         [ 64,  11,  27,  12,   5,  16],\n",
      "         [ 52,  35,  27,  12,   5,  73],\n",
      "         [ 36,  19,  27,  12,   5, 115],\n",
      "         [ 48,  28,  27,  12,   5,   7],\n",
      "         [ 55,  16,  27,  12,   5,  99],\n",
      "         [ 43,   0,  27,  20,   5,  65],\n",
      "         [ 47,  27,  27,  20,   5,  32],\n",
      "         [ 57,   0,  27,  20,   5, 105],\n",
      "         [ 48,  27,  27,  20,   5,  70],\n",
      "         [ 60,  11,  27,  20,   5,  51],\n",
      "         [ 57,  17,  27,  20,   5,  51],\n",
      "         [ 55,  12,  27,  20,   5,  10],\n",
      "         [ 48,  22,  27,  24,   5, 129],\n",
      "         [ 48,   2,  27,  24,   5,  21],\n",
      "         [ 47,  17,  27,  24,   5,  55],\n",
      "         [ 43,  21,  27,  25,   5,  16],\n",
      "         [ 45,  14,  27,  26,   5,  93],\n",
      "         [ 48,  31,  27,  26,   5,  65],\n",
      "         [ 60,  17,  27,  33,   5,  48],\n",
      "         [ 43,   7,  27,  33,   5,  55],\n",
      "         [ 47,  30,  27,  28,   5,  16],\n",
      "         [ 52,  20,  27,  28,   5,  19],\n",
      "         [ 48,  16,  27,  28,   5,  42],\n",
      "         [ 52,  15,  27,  28,   5,  16],\n",
      "         [ 54,  11,  27,  26,   5,  21],\n",
      "         [ 48,   4,  43,  28,   5,  16],\n",
      "         [ 52,  10,  27,  28,   5,   6],\n",
      "         [ 57,  18,  27,   4,   5,  73],\n",
      "         [ 48,  16,  27,   4,   5,  61],\n",
      "         [ 52,  10,  27,   4,   5,  16],\n",
      "         [ 36,  13,  27,   4,   5,  15],\n",
      "         [ 55,  15,  27,   4,   5,  73],\n",
      "         [ 60,  24,  27,   4,   5,  65],\n",
      "         [ 52,  30,  27,   4,   5,  21],\n",
      "         [ 45,  20,  27,   4,   5, 104],\n",
      "         [ 45,  16,  27,   9,   5,  21],\n",
      "         [ 52,  28,  27,  24,   5,  21],\n",
      "         [ 57,  12,  27,  24,   5,  16],\n",
      "         [ 43,   5,  27,  24,   5,  30],\n",
      "         [ 43,  14,  27,  28,   5,  30],\n",
      "         [ 47,  16,  27,  28,   5,  65],\n",
      "         [ 55,  33,  27,  28,   5,  53],\n",
      "         [ 47,  31,  27,  28,   5,  53],\n",
      "         [ 43,  30,  27,  24,   5,  57],\n",
      "         [ 47,   8,  27,  24,   5,  57],\n",
      "         [ 48,  12,  27,  24,   5,  16],\n",
      "         [ 52,  27,  27,  24,   5,  73],\n",
      "         [ 54,  35,  27,  28,   5,   9],\n",
      "         [ 36,  17,  27,  28,   5,  31],\n",
      "         [ 50,  13,  27,  28,   5,  30],\n",
      "         [ 45,  31,  27,  28,   5,  57],\n",
      "         [ 48,  16,  27,  27,   5,  20],\n",
      "         [ 50,   5,  27,  28,   5,  93],\n",
      "         [ 36,   9,  27,  34,   5,   6],\n",
      "         [ 41,   4,  27,  26,   5,   9],\n",
      "         [ 50,   4,  27,  33,   5,  84],\n",
      "         [ 43,  32,  27,  33,   5,  84],\n",
      "         [ 48,  33,  27,   2,   5,  12],\n",
      "         [ 36,  33,  27,  20,   5,  73],\n",
      "         [ 47,  23,  27,  20,   5, 125],\n",
      "         [ 50,  35,  27,  20,   5,  54],\n",
      "         [ 52,  28,  27,  20,   5,  10],\n",
      "         [ 57,  12,  27,  20,   5,  10],\n",
      "         [ 40,  16,  27,  20,   5,   8],\n",
      "         [ 43,   5,  27,  20,   5,   9],\n",
      "         [ 45,   4,  27,  20,   5,  53],\n",
      "         [ 48,  21,  27,  33,   5,  57],\n",
      "         [ 52,  19,  27,  33,   5,  11],\n",
      "         [ 50,  12,  27,  34,   5,  76],\n",
      "         [ 48,   7,  27,  17,   5, 113],\n",
      "         [ 43,  13,  27,  18,   5,  33],\n",
      "         [ 43,  12,  27,  18,   5,  51],\n",
      "         [ 43,  17,  27,  19,   5, 124],\n",
      "         [ 46,  16,  27,  28,   5,  61],\n",
      "         [ 36,  14,  27,  28,   5,  68],\n",
      "         [ 43,   2,  27,  28,   5,  51],\n",
      "         [ 52,  34,  27,  28,   5,  16],\n",
      "         [ 47,  23,  27,  28,   5,   9],\n",
      "         [ 50,  18,  27,  28,   5,  16],\n",
      "         [ 48,  22,  27,  28,   5,  54],\n",
      "         [ 48,  25,  27,  28,   5,  28],\n",
      "         [ 52,  25,  27,  28,   5,  57],\n",
      "         [ 52,  17,  27,  28,   5,  73],\n",
      "         [ 47,   5,  27,  28,   5,  16],\n",
      "         [ 48,  21,  27,  12,   5,  37],\n",
      "         [ 48,  29,  27,  12,   5,  65],\n",
      "         [ 48,  30,  27,  12,   5,  28],\n",
      "         [ 48,  21,  27,  12,   5,  28],\n",
      "         [ 50,  26,  27,  12,   5, 104],\n",
      "         [ 45,  17,  27,  12,   5,  12],\n",
      "         [ 48,  16,  27,  12,   5,  51],\n",
      "         [ 55,  11,  27,  12,   5,  48],\n",
      "         [ 67,  11,  27,  12,   5, 104],\n",
      "         [ 45,   0,  27,  12,   5,  30],\n",
      "         [ 48,  28,  27,  12,   5,  57],\n",
      "         [ 52,  18,  27,  12,   5,  59],\n",
      "         [ 43,  10,  27,  12,   5,  70],\n",
      "         [ 50,   3,  27,  12,   5,  73],\n",
      "         [ 47,   7,  27,  20,   5,  57],\n",
      "         [ 50,  25,  27,  20,   5,  49],\n",
      "         [ 55,  27,  27,  20,   5,  59],\n",
      "         [ 59,  15,  27,  20,   5,  16],\n",
      "         [ 36,  14,  27,  20,   5,  16],\n",
      "         [ 43,  35,  27,  20,   5,  80],\n",
      "         [ 50,  24,  27,  24,   5,  16],\n",
      "         [ 43,  11,  27,  27,   5,  16],\n",
      "         [ 50,  18,  27,  28,   5,  31],\n",
      "         [ 43,  32,  27,  28,   5,  72],\n",
      "         [ 50,  16,  27,  28,   5,  16],\n",
      "         [ 54,  16,  27,  32,   5,   5],\n",
      "         [ 36,  26,  27,  34,   5,  12],\n",
      "         [ 48,  34,  27,  33,   5,  21],\n",
      "         [ 47,  17,  27,  32,   5,  21],\n",
      "         [ 48,  11,  27,  32,   5,  11],\n",
      "         [ 60,  11,  27,  32,   5,  16],\n",
      "         [ 36,   9,  27,  32,   5,  16],\n",
      "         [ 48,  25,  27,  32,   5, 121],\n",
      "         [ 57,   2,  27,  33,   5,  57],\n",
      "         [ 48,  30,  27,  12,   5,  37],\n",
      "         [ 57,  31,  27,  12,   5,  46],\n",
      "         [ 45,  31,  27,  12,   5,  73],\n",
      "         [ 48,  20,  27,  12,   5,  16],\n",
      "         [ 57,  17,  27,  14,   5, 115],\n",
      "         [ 55,  23,  27,  28,   5, 113],\n",
      "         [ 48,  25,  27,  31,   5,  40],\n",
      "         [ 52,  34,  27,  34,   5,  93],\n",
      "         [ 54,  23,  27,  32,   5,  57],\n",
      "         [ 36,  33,  27,   4,   5,  47],\n",
      "         [ 45,  14,  27,   4,   5,  73],\n",
      "         [ 48,  10,  27,   4,   5,  76],\n",
      "         [ 48,  34,  27,   4,   5,  31],\n",
      "         [ 55,  18,  27,   4,   5,  11],\n",
      "         [ 45,  24,  27,   4,   5,  24],\n",
      "         [ 50,  12,  27,   4,   5,  76],\n",
      "         [ 45,  11,  27,   4,   5,  13],\n",
      "         [ 48,  20,  27,   4,   5,  59],\n",
      "         [ 48,  19,  27,   4,   5,  53],\n",
      "         [ 57,  19,  27,   4,   5,  16],\n",
      "         [ 50,  33,  27,   4,   5,  73],\n",
      "         [ 59,  24,  27,   4,   5,  76],\n",
      "         [ 38,  29,  27,   4,   5,  24],\n",
      "         [ 47,  22,  27,   4,   5,  55],\n",
      "         [ 31,  31,  27,   4,   5,  74],\n",
      "         [ 48,  21,  27,   4,   5,  53],\n",
      "         [ 50,  19,  27,   4,   5,  93],\n",
      "         [ 43,   4,  27,  13,   5, 100],\n",
      "         [ 48,   4,  27,   7,   5,  24],\n",
      "         [ 52,  24,  27,  16,   5,  57],\n",
      "         [ 57,  23,  27,  16,   5,  32],\n",
      "         [ 45,  29,  27,  16,   5,  16],\n",
      "         [ 52,  16,  27,  16,   5,  16],\n",
      "         [ 43,  19,  27,  16,   5,  70],\n",
      "         [ 48,  34,  27,  17,   5,  84],\n",
      "         [ 48,  33,  27,  13,   5, 104],\n",
      "         [ 52,  10,  27,  20,   5,  51],\n",
      "         [ 52,  17,  27,  20,   5,  16],\n",
      "         [ 54,  29,  27,  20,   5,  12],\n",
      "         [ 48,  16,  27,  20,   5,   4],\n",
      "         [ 55,  16,  27,  20,   5,  40],\n",
      "         [ 50,  13,  27,  20,   5,  33],\n",
      "         [ 52,  27,  27,   4,   5,  15],\n",
      "         [ 55,  22,  27,   4,   5,  73],\n",
      "         [ 45,  11,  27,   4,   5,  57],\n",
      "         [ 48,  28,  27,   4,   5,  21],\n",
      "         [ 48,  20,  27,   6,   5,  21],\n",
      "         [ 57,  18,  27,   8,   5,  16],\n",
      "         [ 43,  35,  27,   8,   5,   7],\n",
      "         [ 52,  22,  27,   8,   5,  16],\n",
      "         [ 40,  11,  27,   9,   5,  24],\n",
      "         [ 46,  16,  27,  20,   5,  15],\n",
      "         [ 36,  19,  27,  20,   5, 104],\n",
      "         [ 52,   2,  27,  20,   5,  16],\n",
      "         [ 59,  19,  27,  20,   5,  32],\n",
      "         [ 43,  27,  27,  20,   5,  11],\n",
      "         [ 45,  26,  27,  20,   5,  59],\n",
      "         [ 48,  24,  27,   4,   5, 105],\n",
      "         [ 60,  24,  27,   4,   5, 105],\n",
      "         [ 43,  32,  27,   4,   5,  55],\n",
      "         [ 47,  21,  27,   4,   5,  55],\n",
      "         [ 48,  32,  27,   4,   5, 108],\n",
      "         [ 52,  25,  27,   4,   5,  51],\n",
      "         [ 45,  15,  27,   4,   5,   5],\n",
      "         [ 47,  19,  27,   4,   5,  16],\n",
      "         [ 52,   9,  27,   8,   5,  40],\n",
      "         [ 55,   4,  27,  12,   5, 115],\n",
      "         [ 54,  15,  27,  12,   5,  21],\n",
      "         [ 43,   4,  27,  12,   5,  16],\n",
      "         [ 47,   4,  27,  12,   5, 115],\n",
      "         [ 55,  28,  27,  12,   5,  89],\n",
      "         [ 52,  19,  27,  12,   5,  37],\n",
      "         [ 60,  13,  27,  12,   5, 104],\n",
      "         [ 50,  12,  27,  16,   5,  28],\n",
      "         [ 54,  31,  27,  16,   5,  38],\n",
      "         [ 43,  16,  27,  16,   5,  12],\n",
      "         [ 48,  15,  27,   9,   5,  70],\n",
      "         [ 45,  35,  27,  10,   5,  16],\n",
      "         [ 49,  28,  27,  16,   5,  73],\n",
      "         [ 52,  17,  27,  12,   5,   9],\n",
      "         [ 52,  29,  27,  12,   5,  53],\n",
      "         [ 47,  12,  27,  12,   5,  93],\n",
      "         [ 45,  20,  27,  19,   5,  15],\n",
      "         [ 48,  33,  27,  20,   5,  15],\n",
      "         [ 50,  27,  27,  20,   5,  51],\n",
      "         [ 55,  18,  27,  20,   5,  51],\n",
      "         [ 45,  35,  27,  12,   5, 104],\n",
      "         [ 45,  22,  27,  27,   5,  15],\n",
      "         [ 48,  18,  27,  28,   5,  73],\n",
      "         [ 43,  17,  27,  28,   5,  53],\n",
      "         [ 48,  20,  27,   4,   5,   4],\n",
      "         [ 52,  17,  27,   4,   5, 116],\n",
      "         [ 50,  31,  27,   4,   5,  37],\n",
      "         [ 48,   4,  27,   4,   5,  15],\n",
      "         [ 52,  12,  27,   8,   5,  73],\n",
      "         [ 47,  34,  27,  26,   5,  16],\n",
      "         [ 50,  31,  27,  16,   5,  62],\n",
      "         [ 47,  28,  27,  16,   5,  32],\n",
      "         [ 36,  28,  27,  18,   5,  59],\n",
      "         [ 48,   7,  27,  18,   5,   6],\n",
      "         [ 47,  12,  27,  18,   5,   4],\n",
      "         [ 45,   4,  27,  17,   5, 119],\n",
      "         [ 47,  14,  27,  22,   5,   4],\n",
      "         [ 54,  10,  27,  28,   5,  65],\n",
      "         [ 48,  28,  27,  28,   5,  11],\n",
      "         [ 36,  27,  27,  28,   5,  15],\n",
      "         [ 45,  24,  27,  28,   5,  59],\n",
      "         [ 48,  24,  27,  28,   5,  34],\n",
      "         [ 48,  19,  27,  28,   5,  16],\n",
      "         [ 48,  18,  27,  28,   5,  60],\n",
      "         [ 50,  22,  27,  28,   5, 104],\n",
      "         [ 45,  29,  27,  28,   5,  75],\n",
      "         [ 48,  24,  27,  28,   5,   5],\n",
      "         [ 48,  21,  27,   4,   5,  15],\n",
      "         [ 52,  15,  27,   4,   5,  79],\n",
      "         [ 45,  19,  27,   4,   5,  10],\n",
      "         [ 48,  30,  27,   4,   5,  65],\n",
      "         [ 48,   4,  27,   4,   5,  30],\n",
      "         [ 52,  13,  27,   6,   5,  16],\n",
      "         [ 38,  21,  27,   6,   5,  57],\n",
      "         [ 46,  34,  27,   6,   5,  79],\n",
      "         [ 50,  21,  27,   6,   5,  55],\n",
      "         [ 54,  17,  27,  23,   5,   6],\n",
      "         [ 47,  17,  27,   4,   5,  37],\n",
      "         [ 50,  20,  27,   4,   5,   4],\n",
      "         [ 52,  10,  27,   4,   5,   4],\n",
      "         [ 38,  14,  27,   4,   5,  55],\n",
      "         [ 45,  18,  27,  21,   5,  40],\n",
      "         [ 45,   1,  27,  22,   5,  77],\n",
      "         [ 57,  24,  27,  26,   5, 124],\n",
      "         [ 47,   3,  27,  26,   5,  51],\n",
      "         [ 36,  30,  27,  12,   5,  93],\n",
      "         [ 43,  30,  27,  12,   5,  56],\n",
      "         [ 48,   8,  27,  12,   5,  59],\n",
      "         [ 52,  11,  27,   8,   5,  59],\n",
      "         [ 47,  26,  27,   8,   5,  74],\n",
      "         [ 48,  33,  27,  11,   5,  74],\n",
      "         [ 52,  33,  27,  12,   5, 110],\n",
      "         [ 52,  12,  27,  12,   5,  53],\n",
      "         [ 52,  31,  27,  12,   5,  16],\n",
      "         [ 59,  23,  27,  12,   5,  30],\n",
      "         [ 47,  23,  27,  12,   5,   4],\n",
      "         [ 36,  31,  27,  26,   5,  83],\n",
      "         [ 43,  16,  27,  26,   5,  84],\n",
      "         [ 36,  32,  27,  26,   5, 115],\n",
      "         [ 48,   4,  27,   7,   5,   9],\n",
      "         [ 45,   2,  27,   8,   5,  16],\n",
      "         [ 50,  35,  27,   9,   5, 104],\n",
      "         [ 45,  25,  27,   4,   5,  59],\n",
      "         [ 48,  31,  27,   4,   5,  84],\n",
      "         [ 48,  23,  27,   4,   5,  59],\n",
      "         [ 52,  26,  27,   4,   5,  59],\n",
      "         [ 47,  12,  27,   4,   5,  16],\n",
      "         [ 45,  34,  27,   4,   5,  71],\n",
      "         [ 43,  22,  27,   4,   5,  59],\n",
      "         [ 47,   6,  27,   4,   5,  35],\n",
      "         [ 48,  25,  27,   4,   5,  48],\n",
      "         [ 48,  19,  27,   4,   5,  38],\n",
      "         [ 43,  28,  27,   9,   5, 100],\n",
      "         [ 48,  27,  27,   9,   5,   9],\n",
      "         [ 47,  26,  27,   8,   5,   9],\n",
      "         [ 48,   9,  27,   8,   5,  59],\n",
      "         [ 43,  32,  27,  28,   5,   4],\n",
      "         [ 55,  19,  27,  28,   5,  30],\n",
      "         [ 60,  35,  27,  12,   5,  32],\n",
      "         [ 45,  33,  27,  17,   5,  13],\n",
      "         [ 47,  18,  27,  17,   5, 129],\n",
      "         [ 48,  31,  27,  17,   5,  16],\n",
      "         [ 48,  23,  27,  17,   5,  37],\n",
      "         [ 55,  17,  27,  17,   5,  32],\n",
      "         [ 67,  16,  27,  20,   5,  40],\n",
      "         [ 48,   8,  27,  20,   5,  30],\n",
      "         [ 36,  25,  27,  20,   5,  79],\n",
      "         [ 47,  28,  27,  20,   5,   6],\n",
      "         [ 52,   6,  27,  20,   5,  55],\n",
      "         [ 48,   9,  27,  20,   5,  76],\n",
      "         [ 48,  10,  27,  20,   5,  48],\n",
      "         [ 47,  10,  27,  23,   5,  51],\n",
      "         [ 45,  16,  27,  24,   5,  74],\n",
      "         [ 36,  34,  27,  24,   5,  70],\n",
      "         [ 52,  26,  27,   4,   5,   8],\n",
      "         [ 57,  16,  27,   4,   5,   8],\n",
      "         [ 33,  19,  27,   4,   5,  57],\n",
      "         [ 48,   9,  27,   4,   5,  57],\n",
      "         [ 48,  23,  27,   4,   5,  73],\n",
      "         [ 48,  25,  27,   4,   5,  85],\n",
      "         [ 57,   9,  27,   4,   5,  83],\n",
      "         [ 48,  23,  27,   9,   5,  11],\n",
      "         [ 52,  13,  27,  11,   5,   7],\n",
      "         [ 52,  17,  27,  12,   5,   2],\n",
      "         [ 57,   0,  27,  12,   5,  16],\n",
      "         [ 48,  25,  27,  12,   5,  57],\n",
      "         [ 52,  16,  27,  12,   5,  16],\n",
      "         [ 45,  19,  27,   4,   5,  93],\n",
      "         [ 48,  24,  27,   4,   5,  11],\n",
      "         [ 52,  21,  27,   4,   5,   9],\n",
      "         [ 48,  35,  27,   4,   5,  59],\n",
      "         [ 48,  28,  27,   4,   5,  45],\n",
      "         [ 55,   3,  27,   4,   5,  41],\n",
      "         [ 67,  35,  27,   4,   5, 104],\n",
      "         [ 40,  33,  27,   4,   5,  65],\n",
      "         [ 47,  30,  27,   4,   5,  85],\n",
      "         [ 43,  18,  27,   4,   5,  73],\n",
      "         [ 45,  28,  27,   4,   5,  59],\n",
      "         [ 52,  21,  27,   4,   5,  57],\n",
      "         [ 36,  19,  27,   4,   5, 116],\n",
      "         [ 52,  25,  27,   4,   5,  65],\n",
      "         [ 47,  29,  27,   4,   5,  51],\n",
      "         [ 50,  17,  27,   4,   5,  59],\n",
      "         [ 57,  17,  27,   4,   5,  18],\n",
      "         [ 36,  22,  27,   4,   5,  59],\n",
      "         [ 45,  28,  27,   2,   5,  65],\n",
      "         [ 47,  17,  27,  26,   5,  73],\n",
      "         [ 47,  28,  27,  17,   5,  93],\n",
      "         [ 50,  27,  27,  17,   5,  61],\n",
      "         [ 50,  14,  27,  12,   5,  10],\n",
      "         [ 48,  13,  27,  12,   5,  54],\n",
      "         [ 48,  16,  27,  12,   5,  57],\n",
      "         [ 50,  12,  27,  12,   5,  57],\n",
      "         [ 50,  17,  27,  12,   5,  16],\n",
      "         [ 54,   2,  27,  12,   5,  84],\n",
      "         [ 57,  21,  27,  12,   5, 104],\n",
      "         [ 43,  11,  27,  12,   5,  16],\n",
      "         [ 46,  21,  27,  12,   5,  16],\n",
      "         [ 45,  15,  27,  14,   5,  59],\n",
      "         [ 45,   2,  27,  19,   5,  57],\n",
      "         [ 48,  32,  27,  20,   5,  78],\n",
      "         [ 45,  17,  27,  20,   5,  16],\n",
      "         [ 50,  20,  27,  26,   5,  93],\n",
      "         [ 43,  33,  27,  26,   5,  15],\n",
      "         [ 47,  21,  27,  17,   5,  53],\n",
      "         [ 48,  21,  27,  18,   5,   9],\n",
      "         [ 50,  31,  27,  20,   5,   9],\n",
      "         [ 43,  20,  27,  20,   5,  15],\n",
      "         [ 48,  19,  27,  20,   5,  15],\n",
      "         [ 57,  16,  27,  20,   5,  21],\n",
      "         [ 43,  27,  27,  20,   5,  62],\n",
      "         [ 55,  23,  27,  20,   5,  16],\n",
      "         [ 31,  24,  27,  20,   5,   4],\n",
      "         [ 46,  16,  27,  20,   5,  51],\n",
      "         [ 53,  17,  27,  20,   5,  61],\n",
      "         [ 36,  12,  27,   4,   5,  12],\n",
      "         [ 48,   6,  27,   4,   5,  41],\n",
      "         [ 52,  17,  27,   4,   5,  21],\n",
      "         [ 52,  10,  27,   4,   5,  70],\n",
      "         [ 38,   5,  27,   4,   5,   2],\n",
      "         [ 48,  16,  27,   4,   5,  16],\n",
      "         [ 52,  10,  27,   4,   5,  16],\n",
      "         [ 48,   7,  27,   4,   5, 108],\n",
      "         [ 36,  20,  27,   4,   5,  73],\n",
      "         [ 48,   4,  27,   4,   5,  76],\n",
      "         [ 47,  19,  27,   4,   5,  75],\n",
      "         [ 48,  23,  27,   5,   5,  80],\n",
      "         [ 53,  16,  27,   4,   5,  70],\n",
      "         [ 41,  17,  27,   4,   5,  15],\n",
      "         [ 47,  29,  27,   4,   5,  16],\n",
      "         [ 31,  24,  27,   4,   5,  16],\n",
      "         [ 36,  20,  27,   4,   5,  40],\n",
      "         [ 43,   2,  27,   4,   5,  16],\n",
      "         [ 48,  19,  27,   4,   5,  16],\n",
      "         [ 48,  15,  27,   4,   5,  65],\n",
      "         [ 48,  10,  27,   4,   5,  40],\n",
      "         [ 60,  32,  27,   4,   5,  73],\n",
      "         [ 48,  24,  27,   4,   5,  54],\n",
      "         [ 43,  16,  27,   4,   5,  21],\n",
      "         [ 48,  31,  27,   4,   5,  45],\n",
      "         [ 52,  23,  27,   4,   5,  61],\n",
      "         [ 43,  14,  27,   4,   5,  70],\n",
      "         [ 47,  32,  27,   4,   5,  51],\n",
      "         [ 48,  21,  27,   4,   5,  59],\n",
      "         [ 50,  25,  27,   4,   5,  59],\n",
      "         [ 48,  17,  27,   4,   5,  59],\n",
      "         [ 36,  28,  27,   4,   5,  21],\n",
      "         [ 45,  19,  27,   8,   5,  16],\n",
      "         [ 47,  32,  27,   8,   5,   6],\n",
      "         [ 36,   3,  27,   8,   5,  25],\n",
      "         [ 41,  25,  27,  34,   5,  65],\n",
      "         [ 48,   4,  27,  34,   5, 108],\n",
      "         [ 45,   2,  27,   4,   5,  16],\n",
      "         [ 45,  14,  27,   4,   5,  68],\n",
      "         [ 57,  22,  27,   8,   5,   7],\n",
      "         [ 48,  25,  27,   8,   5,  97],\n",
      "         [ 46,  25,  27,   8,   5,  19],\n",
      "         [ 46,  29,  27,   9,   5,   4],\n",
      "         [ 50,  29,  27,   9,   5,  16],\n",
      "         [ 52,  11,  27,  10,   5,  17],\n",
      "         [ 48,  18,  27,  10,   5, 104],\n",
      "         [ 48,  33,  27,  10,   5,  51],\n",
      "         [ 60,  33,  27,  10,   5,  29],\n",
      "         [ 52,  24,  27,   4,   5,  16],\n",
      "         [ 43,  32,  27,   4,   5,  16],\n",
      "         [ 45,  23,  27,   4,   5,  61],\n",
      "         [ 45,  24,  27,   4,   5,  37],\n",
      "         [ 48,  26,  27,   4,   5,  61],\n",
      "         [ 43,  17,  27,   4,   5,  73],\n",
      "         [ 48,  24,  27,   4,   5,  81],\n",
      "         [ 36,  10,  27,   4,   5,  16],\n",
      "         [ 36,  22,  27,   2,   5,  16],\n",
      "         [ 36,  22,  27,  10,   5,   9],\n",
      "         [ 48,  31,  27,   4,   5,  16],\n",
      "         [ 40,  31,  27,   4,   5,   9],\n",
      "         [ 46,  34,  27,   4,   5,  59],\n",
      "         [ 41,  25,  27,   7,   5, 126],\n",
      "         [ 45,  27,  27,  24,   5, 107],\n",
      "         [ 48,  29,  27,  28,   5,  21],\n",
      "         [ 60,  35,  27,  28,   5, 104],\n",
      "         [ 48,  11,  27,  18,   5,  61],\n",
      "         [ 52,  18,  27,  18,   5,  62],\n",
      "         [ 57,  12,  27,   4,   5,  62],\n",
      "         [ 41,  34,  27,   4,   5,  46],\n",
      "         [ 50,  28,  27,   4,   5,  28],\n",
      "         [ 55,   1,  27,  10,   5,  40],\n",
      "         [ 60,   2,  27,  10,   5,  99],\n",
      "         [ 36,  21,  27,  28,   5, 127],\n",
      "         [ 48,  20,  27,  28,   5,  16],\n",
      "         [ 43,  22,  27,  20,   5,  16],\n",
      "         [ 45,  11,  27,  20,   5,  16]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(profile=\"full\")\n",
    "print(midi_output)\n",
    "torch.set_printoptions(profile=\"default\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b352ae7-33b6-49b5-8313-832e3166b408",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pitch_37', 'Velocity_99', 'Duration_3.0.8', 'Position_0', 'Bar_0', 'Program_95']\n",
      "['Pitch_24', 'Velocity_39', 'Duration_12.0.4', 'Position_0', 'Bar_0', 'Program_84']\n",
      "['Pitch_60', 'Velocity_83', 'Duration_3.0.8', 'Position_0', 'Bar_0', 'Program_20']\n",
      "['Pitch_72', 'Velocity_91', 'Duration_3.0.8', 'Position_0', 'Bar_0', 'Program_68']\n",
      "['Pitch_84', 'Velocity_87', 'Duration_1.0.8', 'Position_0', 'Bar_0', 'Program_52']\n"
     ]
    }
   ],
   "source": [
    "output_Octuple = []\n",
    "\n",
    "for row in midi_output[0]:\n",
    "    tokens = []\n",
    "    for idx, vocab in zip(row, train_data.midi_tokenizer.vocab):\n",
    "        # Use next() with a default value to avoid StopIteration - ensures that value is within range\n",
    "        token = next((key for key, value in vocab.items() if value == min(idx, len(vocab.items())-1)), None)\n",
    "\n",
    "        if token is None:\n",
    "            # If idx is not found, convert vocabulary keys to numeric type and find the closest\n",
    "            print(\"Error detected:\")\n",
    "            print(min(idx, len(vocab.items())))\n",
    "        tokens.append(token)\n",
    "    output_Octuple.append(tokens)\n",
    "\n",
    "for i, row in enumerate(output_Octuple):\n",
    "    print(row)\n",
    "    if i == 4:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "caec5418-0a9e-41c2-a92f-c41fb5c3cc62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Creating the midi file! from octuple\n",
    "gen_midi = train_data.midi_tokenizer(output_Octuple)\n",
    "gen_midi.dump('transformer_output.mid')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:paul] *",
   "language": "python",
   "name": "conda-env-paul-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
